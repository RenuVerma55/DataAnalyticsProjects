{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Project- Amazon top rated Books \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/MB4HWGU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/bX2qT9t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It's a useful technique for creating datasets for research and learning. Mostly it is unstructured html data which is then converted into structured data and stored in spreadsheet or in database format.\n",
    "\n",
    "### The steps we'll follow:\n",
    "\n",
    "- We're going to scrape https://www.amazon.in/gp/bestsellers/books/\n",
    "- We'll get a list of topics.\n",
    "- For each topic, we'll get topic title, topic page URL\n",
    "- For each topic, we'll get the top 50 books in the topic from the topic page\n",
    "- For each book, we'll grab the book name, book URL, author name,book price,star rating and No of customer rated as rating.\n",
    "- Save the information data to CSV file Using Pandas library\n",
    "\n",
    "The output will look like this:\n",
    "\n",
    "title, url ,book_name ,author name ,book price  ,star rating , rating, book_url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/UBu96J0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run the code\n",
    "\n",
    "Option 1: Running using free online resources (1-click, recommended)\n",
    "The easiest way to start executing the code is to click the Run button at the top of this page and select Run on Binder. You can also select \"Run on Colab\" or \"Run on Kaggle\", but you'll need to create an account on Google Colab or Kaggle to use these platforms.\n",
    "\n",
    "Option 2: Running on your computer locally\n",
    "To run the code on your computer locally, you'll need to set up Python, download the notebook and install the required libraries. We recommend using the Conda distribution of Python. Click the Run button at the top of this page, select the Run Locally option, and follow the instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"renuverma55/web-scraping-top-rated\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/renuverma55/web-scraping-top-rated\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/renuverma55/web-scraping-top-rated'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"Web-scraping-top-rated \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the list of books from Amazon\n",
    "\n",
    " - We will use Requests library to downlaod the page.\n",
    " - we will use BeautifulSoup to parse and extract information.\n",
    " - convert to a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a web page using requests\n",
    "\n",
    "When you access a URL like using a web browser, it downloads the contents of the web page the URL points to and displays the output on the screen. Before we can extract information from a web page, we need to download the page using Python.\n",
    "\n",
    "We'll use a library called requests to download web pages from the internet. We can download a web page using the requests.get function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url = 'https://www.amazon.in/gp/bestsellers/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the request was successful, response.status_code is set to a value between 200 and 299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the web page can be accessed using the .text property of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306693"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents = response.text\n",
    "len(page_contents)    #The `len` fucnction tells us the length of the response object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page contains over 306693 characters! Let's view the first 1000 characters of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html lang=\"en-in\" class=\"a-no-js\" data-19ax5a9jf=\"dingo\"><!-- sp:feature:head-start -->\\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset=\"utf-8\"/>\\n<!-- sp:end-feature:head-start -->\\n\\n<!-- sp:feature:cs-optimization -->\\n<meta http-equiv=\\'x-dns-prefetch-control\\' content=\\'on\\'>\\n<link rel=\"dns-prefetch\" href=\"https://images-eu.ssl-images-amazon.com\">\\n<link rel=\"dns-prefetch\" href=\"https://m.media-amazon.com\">\\n<link rel=\"dns-prefetch\" href=\"https://completion.amazon.com\">\\n<!-- sp:end-feature:cs-optimization -->\\n\\n<!-- sp:feature:aui-assets -->\\n<link rel=\"stylesheet\" href=\"https://images-eu.ssl-images-amazon.com/images/I/11EIQ5IGqaL._RC|01ZTHTZObnL.css,41C-I1lXVwL.css,31ufSReDtSL.css,013z33uKh2L.css,017DsKjNQJL.css,0131vqwP5UL.css,41EWOOlBJ9L.css,11TIuySqr6L.css,01ElnPiDxWL.css,11Qjwq-j69L.css,01Dm5eKVxwL.css,01IdKcBuAdL.css,01y-XAlI+2L.css,21P6CS3L9LL.css,01oDR3IULNL.css,41CYNGpGlrL.css,01XPHJk60-L.css,01smHc51S9L.css,21aPhFy+riL.css,11gneA3MtJL.css'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the contents to a file with the .html extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('amazon_bestseller_books.html', 'w') as file:\n",
    "    file.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a HTML File is created by the name amazon_bestseller_books.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/C8jLAfB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the HTML source code using BeautifulSoup library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting HTML in the Browser\n",
    "\n",
    "We can view the source code of any webpage right within your browser by right-clicking anywhere on a page and selecting the \"Inspect\" option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/tXEOKKj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above ,We can find out 'topic title' are present in the \"div\" tag under class  -\"p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to download the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response = requests.get(topic_url)\n",
    "    #Check successful Response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    #Parse using Beautiful Soup\n",
    "    topic_doc = BeautifulSoup(response.text,'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page('https://www.amazon.in/gp/bestsellers/books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_class = '_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8'\n",
    "topic_title_tags = doc.find_all('div',class_=sel_class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_title_tags)  # this is the table lenght which contains topic title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the helper function\n",
    "#### Topic Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(topic_title_tags): # this function is created to get the topic title\n",
    "    topic = topic_title_tags.find('a').text\n",
    "    return topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_topic_titles(topic_title_tags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action & Adventure'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amazon book page contains 35 categories wherein each category 50 best books are listed in the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(topic_title_tags):# this is created to append title in each book\n",
    "    title = []\n",
    "    for j in range(50):\n",
    "        title.append(get_topic_titles(topic_title_tags))\n",
    "    return title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(topic_title_tags): # this function is created to get the topic title url\n",
    "    base_url ='https://www.amazon.in/'\n",
    "    table_tag_href = base_url + topic_title_tags.find('a')['href']\n",
    "    return table_tag_href\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_topic_urls(topic_title_tags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amazon.in//gp/bestsellers/books/1318158031'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(topic_title_tags):   # this is created to append title url in each book category wise.\n",
    "    url = []\n",
    "    for j in range(50):\n",
    "        url.append(get_topic_urls(topic_title_tags))\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_name(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    books_name = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            author_tag = books_tag[i].find('div',class_='zg-grid-general-faceout').find('span').find('div').text\n",
    "            books_name.append(author_tag)\n",
    "        except AttributeError:\n",
    "            books_name.append(None)\n",
    "    return books_name\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_name = get_books_name(get_topic_page(b)) # b contains the url for the  first topic \"action and adventure\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harry Potter and the Philosopher's Stone\",\n",
       " 'The Silent Patient: The record-breaking, multimillion copy Sunday Times bestselling thriller and Richard & Judy book club pick',\n",
       " 'Something I Never Told You',\n",
       " 'The Complete Novels of Sherlock Holmes',\n",
       " 'A Thousand Kisses Deep']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_name[0:5] # Printing first 5 book name from action and adventure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_url(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    base_url = 'https://www.amazon.in/'\n",
    "    books_url = []\n",
    "    for i in range(len( books_tag)):\n",
    "        url = base_url + books_tag[i].find('a')['href']\n",
    "        books_url.append(url)\n",
    "    return books_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_url = get_books_url(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in//Harry-Potter-Philosophers-Stone-Rowling-ebook/dp/B019PIOJYU/ref=zg_bs_1318158031_1/000-0000000-0000000?pd_rd_i=B019PIOJYU&psc=1',\n",
       " 'https://www.amazon.in//Silent-Patient-Alex-Michaelides/dp/1409181634/ref=zg_bs_1318158031_2/000-0000000-0000000?pd_rd_i=1409181634&psc=1',\n",
       " 'https://www.amazon.in//Something-I-Never-Told-You/dp/0143445901/ref=zg_bs_1318158031_3/000-0000000-0000000?pd_rd_i=0143445901&psc=1',\n",
       " 'https://www.amazon.in//Complete-Novels-Sherlock-Holmes/dp/8175994312/ref=zg_bs_1318158031_4/000-0000000-0000000?pd_rd_i=8175994312&psc=1',\n",
       " 'https://www.amazon.in//Thousand-Kisses-Deep-Novoneel-Chakraborty/dp/014345823X/ref=zg_bs_1318158031_5/000-0000000-0000000?pd_rd_i=014345823X&psc=1']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_url [:5] # printing first 5 URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_name(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    author_name = []\n",
    "    for i in range(len( books_tag)):\n",
    "        author_tag = books_tag[i].find('div',class_='a-row a-size-small').text\n",
    "        author_name.append(author_tag)\n",
    "    return author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name = get_author_name(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['J.K. Rowling',\n",
       " 'Alex Michaelides',\n",
       " 'Shravya Bhinder',\n",
       " 'Arthur Conan Doyle',\n",
       " 'Novoneel Chakraborty']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_price(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    book_price = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            price_tag =books_tag[i].find('span',class_='p13n-sc-price').text\n",
    "            book_price.append(price_tag)\n",
    "        except AttributeError:\n",
    "            book_price.append(None)\n",
    "          \n",
    "    return book_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_price = get_book_price(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹124.95', '₹259.00', '₹175.00', '₹165.00', '₹139.00']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_price[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Star Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_star_rating(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    star_rating = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            star_tag = books_tag[i].find('div',class_='a-icon-row').text[0:3]\n",
    "            star_rating.append(star_tag)\n",
    "        except AttributeError:\n",
    "            star_rating.append(None)\n",
    "    return star_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rating = get_star_rating(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2', '4.4', '4.1', '4.7', '4.6', '4.4', '4.4', '4.4', '4.0', '4.5', '4.8']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_rating[26:37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    rating = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            rating_tag= books_tag[i].find('div',class_='a-icon-row')('span')[1].text\n",
    "            rating.append(rating_tag)\n",
    "        except TypeError:\n",
    "            rating.append(None)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = get_rating(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25,438', '116,881', '1,898', '13,953', None]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a function to put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic_list(main_url):\n",
    "    main_dict = {\n",
    "        'title':[],\n",
    "        'url' :[],\n",
    "        'book_name' :[],\n",
    "        'books_url': [],\n",
    "         'author_name': [],\n",
    "        'book_price': [],\n",
    "         'star_rating': [],\n",
    "        'rating': []\n",
    "        \n",
    "    }\n",
    "    \n",
    "    doc = get_topic_page(main_url)     \n",
    "    sel_class = '_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8'\n",
    "    topic_title_tags = doc.find_all('div',class_=sel_class)\n",
    "    for i in topic_title_tags[1:35]:\n",
    "        title= get_topic_titles(i)\n",
    "        url= get_topic_urls(i)\n",
    "        topic_doc =get_topic_page(url)\n",
    "        main_dict['book_name'].extend(get_books_name(topic_doc))\n",
    "        main_dict['author_name'].extend(get_author_name(topic_doc))\n",
    "        main_dict['book_price'].extend(get_book_price(topic_doc))\n",
    "        main_dict['star_rating'].extend(get_star_rating(topic_doc))\n",
    "        main_dict['rating'].extend(get_rating(topic_doc))\n",
    "        main_dict['books_url'].extend(get_books_url(topic_doc))\n",
    "        main_dict['title'].extend(get_title(i))\n",
    "        main_dict['url'].extend(get_url(i))\n",
    "    df=pd.DataFrame(main_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_df= scrape_topic_list('https://www.amazon.in/gp/bestsellers/books/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>book_name</th>\n",
       "      <th>books_url</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_price</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>https://www.amazon.in//Harry-Potter-Philosophe...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>₹124.95</td>\n",
       "      <td>4.7</td>\n",
       "      <td>25,438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>The Silent Patient: The record-breaking, multi...</td>\n",
       "      <td>https://www.amazon.in//Silent-Patient-Alex-Mic...</td>\n",
       "      <td>Alex Michaelides</td>\n",
       "      <td>₹259.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>116,881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Something I Never Told You</td>\n",
       "      <td>https://www.amazon.in//Something-I-Never-Told-...</td>\n",
       "      <td>Shravya Bhinder</td>\n",
       "      <td>₹175.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>The Complete Novels of Sherlock Holmes</td>\n",
       "      <td>https://www.amazon.in//Complete-Novels-Sherloc...</td>\n",
       "      <td>Arthur Conan Doyle</td>\n",
       "      <td>₹165.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13,953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>A Thousand Kisses Deep</td>\n",
       "      <td>https://www.amazon.in//Thousand-Kisses-Deep-No...</td>\n",
       "      <td>Novoneel Chakraborty</td>\n",
       "      <td>₹139.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>Travel</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>An Unforgettable Journey To Hometown: A travel...</td>\n",
       "      <td>https://www.amazon.in//Unforgettable-Journey-H...</td>\n",
       "      <td>Vivek Shukla</td>\n",
       "      <td>₹99.00</td>\n",
       "      <td>4.6</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>Travel</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Aazadi Mera Brand (Hindi)</td>\n",
       "      <td>https://www.amazon.in//Aazadi-Mera-Brand-Anura...</td>\n",
       "      <td>Anuradha Beniwal</td>\n",
       "      <td>₹158.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>Travel</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Around the World in 80 Trains: A 45,000-Mile A...</td>\n",
       "      <td>https://www.amazon.in//Around-World-80-Trains-...</td>\n",
       "      <td>Monisha Rajesh</td>\n",
       "      <td>₹214.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Travel</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Travels in the Mogul Empire: A.D. 1656-1668</td>\n",
       "      <td>https://www.amazon.in//Travels-Mogul-Empire-16...</td>\n",
       "      <td>Francois Bernier</td>\n",
       "      <td>₹612.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Travel</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Lonely Planet Europe Planning Map (Lonely Plan...</td>\n",
       "      <td>https://www.amazon.in//Lonely-Planet-Europe-Pl...</td>\n",
       "      <td>Lonely Planet</td>\n",
       "      <td>₹719.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                                url  \\\n",
       "0     Action & Adventure  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "1     Action & Adventure  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "2     Action & Adventure  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "3     Action & Adventure  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "4     Action & Adventure  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "...                  ...                                                ...   \n",
       "1695              Travel  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "1696              Travel  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "1697              Travel  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "1698              Travel  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "1699              Travel  https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "\n",
       "                                              book_name  \\\n",
       "0              Harry Potter and the Philosopher's Stone   \n",
       "1     The Silent Patient: The record-breaking, multi...   \n",
       "2                            Something I Never Told You   \n",
       "3                The Complete Novels of Sherlock Holmes   \n",
       "4                                A Thousand Kisses Deep   \n",
       "...                                                 ...   \n",
       "1695  An Unforgettable Journey To Hometown: A travel...   \n",
       "1696                          Aazadi Mera Brand (Hindi)   \n",
       "1697  Around the World in 80 Trains: A 45,000-Mile A...   \n",
       "1698        Travels in the Mogul Empire: A.D. 1656-1668   \n",
       "1699  Lonely Planet Europe Planning Map (Lonely Plan...   \n",
       "\n",
       "                                              books_url           author_name  \\\n",
       "0     https://www.amazon.in//Harry-Potter-Philosophe...          J.K. Rowling   \n",
       "1     https://www.amazon.in//Silent-Patient-Alex-Mic...      Alex Michaelides   \n",
       "2     https://www.amazon.in//Something-I-Never-Told-...       Shravya Bhinder   \n",
       "3     https://www.amazon.in//Complete-Novels-Sherloc...    Arthur Conan Doyle   \n",
       "4     https://www.amazon.in//Thousand-Kisses-Deep-No...  Novoneel Chakraborty   \n",
       "...                                                 ...                   ...   \n",
       "1695  https://www.amazon.in//Unforgettable-Journey-H...          Vivek Shukla   \n",
       "1696  https://www.amazon.in//Aazadi-Mera-Brand-Anura...      Anuradha Beniwal   \n",
       "1697  https://www.amazon.in//Around-World-80-Trains-...        Monisha Rajesh   \n",
       "1698  https://www.amazon.in//Travels-Mogul-Empire-16...      Francois Bernier   \n",
       "1699  https://www.amazon.in//Lonely-Planet-Europe-Pl...         Lonely Planet   \n",
       "\n",
       "     book_price star_rating   rating  \n",
       "0       ₹124.95         4.7   25,438  \n",
       "1       ₹259.00         4.5  116,881  \n",
       "2       ₹175.00         4.3    1,898  \n",
       "3       ₹165.00         4.5   13,953  \n",
       "4       ₹139.00        None     None  \n",
       "...         ...         ...      ...  \n",
       "1695     ₹99.00         4.6      117  \n",
       "1696    ₹158.00         4.7      341  \n",
       "1697    ₹214.00         4.4      997  \n",
       "1698    ₹612.00         4.7       25  \n",
       "1699    ₹719.00         4.4      285  \n",
       "\n",
       "[1700 rows x 8 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the extracted information into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_df.to_csv('top_rated_books.csv',index = None)     #Converting the final Dataframe 'scrape_df' to a CSV File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    " * We may get the list of books listed in the different Next Pages. We may all Create a large Data Frame for Future Analysis. \n",
    " * Explore other more complex websites.\n",
    " * Explore how we might go about scraping data using Selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    " * Install and import libraries\n",
    " * Download and Parse the Best seller HTML page source code using resquest and Beautifulsoup to get item categories topics URL.\n",
    " * Extract information from each page\n",
    " * Creadted Pandas DataFrame using ain Function\n",
    " * Save the information data to CSV file Using Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* Python offical documentation. https://docs.python.org/3/\n",
    "\n",
    "* Aakash N S, Introduction to Web Scraping, 2021. https://jovian.ai/aakashns/python-web-scraping-and-rest-api\n",
    "\n",
    "* Tutorial on HTML: https://www.htmldog.com/guides/html/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"renuverma55/web-scraping-top-rated\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Uploading additional files...\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/renuverma55/web-scraping-top-rated\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/renuverma55/web-scraping-top-rated'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(files=['top_rated_books.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}